## Analysing how Key Audio Features vary across different <br> categories of Valence (Mood) in the *Spotify Tracks Dataset*

This repository contains visualisations created using the *Spotify Tracks Dataset*, (available [here](https://raw.githubusercontent.com/robert-jacques/datavisRProject/refs/heads/main/data/data.csv) and directly from
[Kaggle](https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset)), which is a tabular dataset of music tracks that are available on the popular music streaming platform, Spotify.
Each of the 114,000 tracks in the dataset is associated with a range of audio features, each of which provides a measurement of a particular musical characteristic, across 12 attributes in total.

The aim of the project was to create an informative, composite visualisation using R, and a report containing related reflections, which would answer the research question *How do key audio features vary across different categories of valence?*

The component visualisations were created using R and RStudio, and the code is designed to be run in RStudio. The R code can be found [here](https://raw.githubusercontent.com/robert-jacques/datavisRProject/refs/heads/main/code.R).

The composite visualisation comprises:

Plot 1. Violin Plots with overlayed Boxplots - Distribution of Danceability across each Valence category,
Plot 2. Correlation Matrix of Key Audio Features and Valence,
Plot 3. Density Plots - Density Distributions of Key Audio Features by Valence category,
Plot 4. Bar Charts - Variance of Key Audio Features by Valence category.

 
**The projectâ€™s findings suggest that personalised music recommendations could be enhanced through mood-based categorisation of tracks**
